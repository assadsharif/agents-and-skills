"""
Quality Enforcer MCP Server â€” zero-defect diagnostics with fail-closed semantics.

Tools:
    quality_run_diagnostics      Run full diagnostic session with CLEAN/BLOCKED/UNSAFE output
    quality_classify_error       Classify a raw error message into ErrorClass + Severity
    quality_validate_clean       Check if paths are error-free (returns boolean + findings)
"""

import json
from enum import Enum
from pathlib import Path
from typing import List, Optional

from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, ConfigDict, Field

# ---------------------------------------------------------------------------
# FastMCP server instance
# ---------------------------------------------------------------------------

mcp = FastMCP("quality_enforcer_mcp")

# ---------------------------------------------------------------------------
# Enums (inline, mirroring skill models)
# ---------------------------------------------------------------------------


class ErrorClass(str, Enum):
    SYNTAX = "syntax"
    RUNTIME = "runtime"
    LOGIC = "logic"
    CONFIG = "config"
    DEPENDENCY = "dependency"
    ENVIRONMENT = "environment"
    INTEGRATION = "integration"


class Severity(str, Enum):
    CRITICAL = "critical"
    BLOCKING = "blocking"
    WARNING = "warning"


class FinalState(str, Enum):
    CLEAN = "clean"
    BLOCKED = "blocked"
    UNSAFE = "unsafe"


# ---------------------------------------------------------------------------
# Inline detection logic (self-contained, no external import)
# ---------------------------------------------------------------------------


def _detect_syntax_errors_inline(file_path: str) -> List[dict]:
    """Inline syntax error detection."""
    import ast

    findings = []
    path = Path(file_path)

    if not path.exists():
        findings.append(
            {
                "error_class": "environment",
                "severity": "critical",
                "blocking": True,
                "message": f"File does not exist: {file_path}",
                "file_path": str(path),
                "line_number": None,
                "detection_method": "file_exists_check",
            }
        )
        return findings

    try:
        source = path.read_text(encoding="utf-8")
    except Exception as e:
        findings.append(
            {
                "error_class": "environment",
                "severity": "critical",
                "blocking": True,
                "message": f"Cannot read file: {e}",
                "file_path": str(path),
                "line_number": None,
                "detection_method": "file_read",
            }
        )
        return findings

    try:
        ast.parse(source, filename=str(path))
    except SyntaxError as e:
        findings.append(
            {
                "error_class": "syntax",
                "severity": "critical",
                "blocking": True,
                "message": f"Syntax error: {e.msg}",
                "file_path": str(path),
                "line_number": e.lineno,
                "context": e.text.strip() if e.text else None,
                "detection_method": "ast_parse",
            }
        )

    return findings


def _classify_error_inline(error_message: str) -> dict:
    """Inline error classification heuristic."""
    msg_lower = error_message.lower()

    # Heuristic classification
    if "syntaxerror" in msg_lower or "invalid syntax" in msg_lower:
        return {"error_class": "syntax", "severity": "critical"}
    elif "importerror" in msg_lower or "modulenotfounderror" in msg_lower:
        return {"error_class": "dependency", "severity": "blocking"}
    elif "nameerror" in msg_lower or "attributeerror" in msg_lower:
        return {"error_class": "runtime", "severity": "blocking"}
    elif "assertionerror" in msg_lower:
        return {"error_class": "logic", "severity": "blocking"}
    elif "permission" in msg_lower or "file not found" in msg_lower:
        return {"error_class": "environment", "severity": "critical"}
    elif "timeout" in msg_lower or "connection" in msg_lower:
        return {"error_class": "integration", "severity": "blocking"}
    elif "config" in msg_lower or "environment variable" in msg_lower:
        return {"error_class": "config", "severity": "blocking"}
    else:
        return {"error_class": "runtime", "severity": "blocking"}  # Default


# ---------------------------------------------------------------------------
# Tool input models
# ---------------------------------------------------------------------------


class DiagnosticsInput(BaseModel):
    """Input for quality_run_diagnostics."""

    model_config = ConfigDict(extra="forbid", str_strip_whitespace=True)

    target_paths: List[str] = Field(..., min_length=1, description="Paths to diagnose")
    error_classes: List[str] = Field(
        default_factory=lambda: ["syntax", "runtime", "dependency"],
        description="Error classes to check (syntax, runtime, logic, config, dependency, environment, integration)",
    )
    fail_on_any_error: bool = Field(True, description="Block on ANY error (strict)")
    safe_mode: bool = Field(True, description="Detection-only (no auto-resolution)")


class ClassifyInput(BaseModel):
    """Input for quality_classify_error."""

    model_config = ConfigDict(extra="forbid", str_strip_whitespace=True)

    error_message: str = Field(
        ..., min_length=1, description="Raw error message to classify"
    )


class ValidateInput(BaseModel):
    """Input for quality_validate_clean."""

    model_config = ConfigDict(extra="forbid", str_strip_whitespace=True)

    target_paths: List[str] = Field(..., min_length=1, description="Paths to validate")


# ---------------------------------------------------------------------------
# Tools
# ---------------------------------------------------------------------------


@mcp.tool()
async def quality_run_diagnostics(
    target_paths: list[str],
    error_classes: list[str] | None = None,
    fail_on_any_error: bool = True,
    safe_mode: bool = True,
) -> str:
    """Run full zero-defect diagnostic session with strict fail-closed semantics.

    Returns JSON: {final_state, findings, total_errors, blocking_errors, message}.
    final_state: "clean" (zero errors), "blocked" (errors present), or "unsafe" (stalled).
    GUARANTEES: detects ALL errors, blocks on unresolved, no silent failures.
    """
    parsed = DiagnosticsInput(
        target_paths=target_paths,
        error_classes=error_classes or ["syntax", "runtime", "dependency"],
        fail_on_any_error=fail_on_any_error,
        safe_mode=safe_mode,
    )

    all_findings = []

    # Resolve paths and detect
    for target in parsed.target_paths:
        path = Path(target)
        if path.is_file():
            all_findings.extend(_detect_syntax_errors_inline(str(path)))
        elif path.is_dir():
            for py_file in path.rglob("*.py"):
                all_findings.extend(_detect_syntax_errors_inline(str(py_file)))
        else:
            all_findings.append(
                {
                    "error_class": "environment",
                    "severity": "critical",
                    "blocking": True,
                    "message": f"Invalid path: {target}",
                    "file_path": target,
                    "line_number": None,
                    "detection_method": "path_validation",
                }
            )

    blocking_count = sum(1 for f in all_findings if f["blocking"])
    total_errors = len(all_findings)

    # Fail-closed logic
    if total_errors == 0:
        final_state = "clean"
        message = "CLEAN: Zero errors detected."
    elif parsed.fail_on_any_error or blocking_count > 0:
        final_state = "blocked"
        message = f"BLOCKED: {total_errors} error(s) detected, {blocking_count} blocking. Execution unsafe."
    else:
        final_state = "clean"  # Only warnings, not blocking
        message = f"CLEAN: {total_errors} warning(s) detected, none blocking."

    return json.dumps(
        {
            "status": "success",
            "final_state": final_state,
            "findings": all_findings,
            "total_errors": total_errors,
            "blocking_errors": blocking_count,
            "message": message,
            "notes": [
                f"Checked {len(parsed.target_paths)} path(s)",
                f"Safe mode: {'enabled' if parsed.safe_mode else 'disabled'}",
                f"Fail-on-any: {'yes' if parsed.fail_on_any_error else 'no'}",
            ],
        }
    )


@mcp.tool()
async def quality_classify_error(error_message: str) -> str:
    """Classify a raw error message into ErrorClass + Severity.

    Returns JSON: {error_class, severity, confidence}.
    Uses heuristic keyword matching. For definitive classification, use run_diagnostics.
    """
    parsed = ClassifyInput(error_message=error_message)
    result = _classify_error_inline(parsed.error_message)

    return json.dumps(
        {
            "status": "success",
            "error_class": result["error_class"],
            "severity": result["severity"],
            "confidence": "heuristic",
            "notes": [
                "Classification via keyword heuristic",
                "For definitive classification, run full diagnostics on source files",
            ],
        }
    )


@mcp.tool()
async def quality_validate_clean(target_paths: list[str]) -> str:
    """Check if paths are error-free (boolean check + findings).

    Returns JSON: {is_clean, findings}.
    is_clean: true if ZERO errors, false otherwise. Strict validation.
    """
    parsed = ValidateInput(target_paths=target_paths)

    all_findings = []

    for target in parsed.target_paths:
        path = Path(target)
        if path.is_file():
            all_findings.extend(_detect_syntax_errors_inline(str(path)))
        elif path.is_dir():
            for py_file in path.rglob("*.py"):
                all_findings.extend(_detect_syntax_errors_inline(str(py_file)))

    is_clean = len(all_findings) == 0

    return json.dumps(
        {
            "status": "success",
            "is_clean": is_clean,
            "findings": all_findings,
            "total_errors": len(all_findings),
            "message": (
                "CLEAN: Zero errors."
                if is_clean
                else f"NOT CLEAN: {len(all_findings)} error(s) detected."
            ),
        }
    )


# ---------------------------------------------------------------------------
# Entry point
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    mcp.run(transport="stdio")
